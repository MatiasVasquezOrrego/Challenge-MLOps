{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seleccionar el mejor modelo desarrollado por Juan en el notebook llamado \"to-expose\"\n",
    "* Probar tecnicas adicionales esperando encontrar mejoras en los resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-objetivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Limpiar metodos para que sea más simple llevar a producción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccionar el mejor modelo desarrollado por Juan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos modelos presentan resultados similares en las pruebas realizadas por Juan. Además, puedo observar que no se han resuelto algunas problemáticas importantes, tales como:<br>\n",
    "* ¿Los modelos tienen mucha variabilidad o sesgo?<br>\n",
    "* ¿Cuál es la métrica más importante?<br>\n",
    "* ¿Cómo solucionar el problema de desbalance en los datos?<br>\n",
    "* ¿Que resultados obtendriamos si probamos el origen y destino de los vuelos como características? En los gráficos presentados parecen tener relevancia.<br>\n",
    "* ¿Existe algún dato que se pueda sumar a partir de las ciudades de origen y destino?\n",
    "<br>\n",
    "Por lo tanto, considero necesario realizar los siguientes pasos y elecciones:<br>\n",
    "<br>\n",
    "* XGBoost es una buena elección, ya que se puede utilizar para selección binaria y es ideal para datasets de alta dimensionalidad, como es este caso.<br>\n",
    "* La métrica más importante es probablemente el F1-score, dado el desequilibrio en la variable de target, no queremos que el modelo tenga un alto número de falsos positivos ni de falsos negativos, <br>por lo que F1-score es una buena opción ya que considera tanto la precisión como el recall.<br>\n",
    "* Para solucionar el problema del desbalance, podemos probar con los hiperparámetros scale_pos_weight y class_weight para asignar un peso a cada clase.<br>\n",
    "* Agregar más características. En caso de ser necesario, podemos reducirlas utilizando PCA y/o seleccionando las características más importantes.<br>\n",
    "* No se buscaran features de datos externos dado el tiempo disponible para el challenge\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias para el manejo de los paths\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#librerías de tratamiento de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Librerias de visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Librerias propias de python\n",
    "from datetime import datetime as dt\n",
    "from datetime import date\n",
    "\n",
    "#Modelos y metricas\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Preprocesamiento\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se obtiene el path a data\n",
    "notebooks_path = os.getcwd()\n",
    "main_path = Path(notebooks_path).parent\n",
    "data_path = main_path / \"data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68206, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_path = data_path / \"raw/dataset_SCL.csv\"\n",
    "raw_data = pd.read_csv(raw_data_path)\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68206 entries, 0 to 68205\n",
      "Data columns (total 18 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Fecha-I    68206 non-null  object\n",
      " 1   Vlo-I      68206 non-null  object\n",
      " 2   Ori-I      68206 non-null  object\n",
      " 3   Des-I      68206 non-null  object\n",
      " 4   Emp-I      68206 non-null  object\n",
      " 5   Fecha-O    68206 non-null  object\n",
      " 6   Vlo-O      68205 non-null  object\n",
      " 7   Ori-O      68206 non-null  object\n",
      " 8   Des-O      68206 non-null  object\n",
      " 9   Emp-O      68206 non-null  object\n",
      " 10  DIA        68206 non-null  int64 \n",
      " 11  MES        68206 non-null  int64 \n",
      " 12  AÑO        68206 non-null  int64 \n",
      " 13  DIANOM     68206 non-null  object\n",
      " 14  TIPOVUELO  68206 non-null  object\n",
      " 15  OPERA      68206 non-null  object\n",
      " 16  SIGLAORI   68206 non-null  object\n",
      " 17  SIGLADES   68206 non-null  object\n",
      "dtypes: int64(3), object(15)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se copia el dataframe para probar más facilmente los métodos originales\n",
    "df = raw_data.copy(deep=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se contrastan los métodos originales con los nuevos tanto en clean code como en tiempos de operación. <br>\n",
    "Queda tener en cuenta que los tiempos varian según el procesador pero se busca dar un resultado aproximado de la diferencia de ambos metodos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo si el vuelo llego atrazado o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodo original\n",
    "def dif_min(data):\n",
    "    fecha_o = dt.strptime(data['Fecha-O'], '%Y-%m-%d %H:%M:%S')\n",
    "    fecha_i = dt.strptime(data['Fecha-I'], '%Y-%m-%d %H:%M:%S')\n",
    "    dif_min = ((fecha_o - fecha_i).total_seconds())/60\n",
    "    return dif_min\n",
    "\n",
    "df['dif_min'] = df.apply(dif_min, axis = 1)\n",
    "df['atraso_15'] = np.where(df['dif_min'] > 15, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevo metodo\n",
    "raw_data = raw_data.astype({'Fecha-O': \"datetime64\", 'Fecha-I': \"datetime64\"})\n",
    "\n",
    "def add_delay_status_column(raw_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    time_difference = raw_data['Fecha-O'] - raw_data['Fecha-I']\n",
    "    minutes_difference = time_difference.dt.seconds.div(60).astype(int)\n",
    "    raw_data['delay_status'] = minutes_difference > 15\n",
    "    raw_data.loc[raw_data['Fecha-O'] < raw_data['Fecha-I'], 'delay_status'] = False\n",
    "    return raw_data\n",
    "\n",
    "test = add_delay_status_column(raw_data=raw_data).astype({'delay_status': int})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método nuevo resulta ser aprox 766% más rápido"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrar si es temporada alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método original\n",
    "def temporada_alta(fecha):\n",
    "    fecha_año = int(fecha.split('-')[0])\n",
    "    fecha = dt.strptime(fecha, '%Y-%m-%d %H:%M:%S')\n",
    "    range1_min = dt.strptime('15-Dec', '%d-%b').replace(year = fecha_año)\n",
    "    range1_max = dt.strptime('31-Dec', '%d-%b').replace(year = fecha_año)\n",
    "    range2_min = dt.strptime('1-Jan', '%d-%b').replace(year = fecha_año)\n",
    "    range2_max = dt.strptime('3-Mar', '%d-%b').replace(year = fecha_año)\n",
    "    range3_min = dt.strptime('15-Jul', '%d-%b').replace(year = fecha_año)\n",
    "    range3_max = dt.strptime('31-Jul', '%d-%b').replace(year = fecha_año)\n",
    "    range4_min = dt.strptime('11-Sep', '%d-%b').replace(year = fecha_año)\n",
    "    range4_max = dt.strptime('30-Sep', '%d-%b').replace(year = fecha_año)\n",
    "    \n",
    "    if ((fecha >= range1_min and fecha <= range1_max) or \n",
    "        (fecha >= range2_min and fecha <= range2_max) or \n",
    "        (fecha >= range3_min and fecha <= range3_max) or\n",
    "        (fecha >= range4_min and fecha <= range4_max)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['temporada_alta'] = df['Fecha-I'].apply(temporada_alta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método nuevo\n",
    "raw_data = raw_data.astype({'Fecha-I': \"datetime64\"})\n",
    "\n",
    "def add_season_status_column(raw_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # High Season cases:\n",
    "    # Dec 15 to Dec 31\n",
    "    # Jan 1 to Mar 3\n",
    "    # Jul 15 to Jul 31\n",
    "    # Sep 11 to Sep 30 \n",
    "    high_season_ranges = [\n",
    "        ((12, 15), (12, 31)),\n",
    "        ((1, 1), (3, 3)),\n",
    "        ((7, 15), (7, 31)),\n",
    "        ((9, 11), (9, 30))\n",
    "    ]\n",
    "    \n",
    "    raw_data['is_high_season'] = raw_data['Fecha-I'].apply(\n",
    "        lambda date: any(\n",
    "            start <= (date.month, date.day) <= end\n",
    "            for start, end in high_season_ranges\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return raw_data\n",
    "\n",
    "test = add_season_status_column(raw_data=raw_data).astype({'is_high_season': int})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método nuevo resulta ser aprox 1225% más rápido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método original\n",
    "def get_periodo_dia(fecha):\n",
    "    fecha_time = dt.strptime(fecha, '%Y-%m-%d %H:%M:%S').time()\n",
    "    mañana_min = dt.strptime(\"05:00\", '%H:%M').time()\n",
    "    mañana_max = dt.strptime(\"11:59\", '%H:%M').time()\n",
    "    tarde_min = dt.strptime(\"12:00\", '%H:%M').time()\n",
    "    tarde_max = dt.strptime(\"18:59\", '%H:%M').time()\n",
    "    noche_min1 = dt.strptime(\"19:00\", '%H:%M').time()\n",
    "    noche_max1 = dt.strptime(\"23:59\", '%H:%M').time()\n",
    "    noche_min2 = dt.strptime(\"00:00\", '%H:%M').time()\n",
    "    noche_max2 = dt.strptime(\"4:59\", '%H:%M').time()\n",
    "    \n",
    "    if(fecha_time > mañana_min and fecha_time < mañana_max):\n",
    "        return 'mañana'\n",
    "    elif(fecha_time > tarde_min and fecha_time < tarde_max):\n",
    "        return 'tarde'\n",
    "    elif((fecha_time > noche_min1 and fecha_time < noche_max1) or\n",
    "         (fecha_time > noche_min2 and fecha_time < noche_max2)):\n",
    "        return 'noche'\n",
    "\n",
    "df['periodo_dia'] = df['Fecha-I'].apply(get_periodo_dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método nuevo\n",
    "raw_data = raw_data.astype({'Fecha-I': \"datetime64\"})\n",
    "\n",
    "def add_day_period_column(raw_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    day_periods = {\n",
    "        'morning': (5, 12),\n",
    "        'afternoon': (12, 19),\n",
    "        'evening_one': (19, 24),\n",
    "        'evening_two': (0, 5)\n",
    "    }\n",
    "    \n",
    "    raw_data['day_period'] = raw_data['Fecha-I'].apply(\n",
    "        lambda datetime: next((period for period, hours in day_periods.items() if hours[0] <= datetime.hour < hours[1]), None)\n",
    "    )\n",
    "\n",
    "    raw_data.loc[raw_data['day_period'].isin(['evening_one', 'evening_two']), 'day_period'] = 'evening'\n",
    "    \n",
    "    return raw_data\n",
    "\n",
    "test = add_day_period_column(raw_data=raw_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método nuevo resulta ser aprox 1566% más rápido "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproceso"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo lo visto en \"to-expose\" se descartan las columnas 'Ori-I', 'Ori-O','Vlo-I', 'Vlo-O', 'OPERA', 'SIGLAORI', 'SIGLADES' ya que alguna de estas se repiten en forma de codigo en otras columnas<br>y algunas no parecen tener importancia. (Estas ultimas se podrian revisar en el caso de que este fuera un analysis más extenso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(raw_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    preprocessed_data = (\n",
    "        raw_data\n",
    "        .drop(columns=['Ori-I', 'Ori-O', 'Vlo-I', 'Vlo-O', 'OPERA', 'SIGLAORI', 'SIGLADES'], errors='ignore')\n",
    "        .dropna()\n",
    "        .astype({\n",
    "            'Fecha-I': \"datetime64\",\n",
    "            'Fecha-O': \"datetime64\",\n",
    "        })\n",
    "    )\n",
    "    return preprocessed_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(preprocessed_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    processed_data = (\n",
    "        preprocessed_data\n",
    "        .pipe(add_day_period_column)\n",
    "        .pipe(add_season_status_column)\n",
    "        .pipe(add_delay_status_column)\n",
    "        .drop(columns=['Fecha-I', 'Fecha-O'], errors='ignore')\n",
    "    )\n",
    "    return processed_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preprocess_data(raw_data=raw_data)\n",
    "processed_data = process_data(preprocessed_data=preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(processed_data, target='delay_status', train_size=0.8, valid_size=0.1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_numpy(X: pd.DataFrame, columns: list) -> np.array:\n",
    "    return X.loc[:, columns].to_numpy()\n",
    "\n",
    "def create_one_hot_encoder(X_train: pd.DataFrame, columns: list) -> OneHotEncoder:\n",
    "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    one_hot_encoder.fit(X_train[columns])\n",
    "    return one_hot_encoder\n",
    "\n",
    "def create_label_encoders(columns_with_values: dict) -> dict:\n",
    "    label_encoders = {}\n",
    "    for column in columns_with_values.keys():\n",
    "        le = LabelEncoder()\n",
    "        le.fit(columns_with_values[column])\n",
    "        label_encoders[column] = le\n",
    "    return label_encoders\n",
    "\n",
    "def encode_one_hot_columns(X: pd.DataFrame, one_hot_encoder: OneHotEncoder) -> np.array:\n",
    "    columns = one_hot_encoder.feature_names_in_.tolist()\n",
    "    return one_hot_encoder.transform(X[columns]).toarray()\n",
    "\n",
    "def encode_label_columns(X: pd.DataFrame, label_encoders: dict) -> np.array:\n",
    "    label_encodes = np.array([])\n",
    "    for column in label_encoders.keys():\n",
    "        results = label_encoders[column].transform(X[column])\n",
    "        results = results.reshape(results.shape[0], 1)\n",
    "        if label_encodes.size == 0: \n",
    "            label_encodes = results\n",
    "            continue\n",
    "        label_encodes = np.concatenate((label_encodes, results), axis=1)\n",
    "    return label_encodes\n",
    "\n",
    "def encode_dataset(X: pd.DataFrame, one_hot_encoder: OneHotEncoder, label_encoders: dict, columns_to_numpy: list) -> np.array:\n",
    "    not_encoded_variables = transform_to_numpy(X=X, columns=columns_to_numpy)\n",
    "    label_encodes = encode_label_columns(X=X, label_encoders=label_encoders)\n",
    "    sparse_encodes = encode_one_hot_columns(X=X, one_hot_encoder=one_hot_encoder)\n",
    "    return np.concatenate([not_encoded_variables, label_encodes, sparse_encodes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns = ['Des-I', 'Emp-I', 'Des-O', 'Emp-O', 'TIPOVUELO', 'is_high_season']\n",
    "one_hot_encoder = create_one_hot_encoder(X_train=X_train, columns=one_hot_columns)\n",
    "\n",
    "label_columns_with_values = {\n",
    "    'DIANOM': [\"Lunes\", \"Martes\", \"Miercoles\", \"Jueves\", \"Viernes\", \"Sabado\", \"Domingo\"], \n",
    "    'day_period': [\"morning\", \"afternoon\", \"evening\"]\n",
    "}\n",
    "label_encoders = create_label_encoders(columns_with_values=label_columns_with_values)\n",
    "\n",
    "columns_to_numpy = ['DIA', 'MES', 'AÑO']\n",
    "\n",
    "X_train_encoded = encode_dataset(X=X_train, one_hot_encoder=one_hot_encoder, label_encoders=label_encoders, columns_to_numpy=columns_to_numpy)\n",
    "X_valid_encoded = encode_dataset(X=X_valid, one_hot_encoder=one_hot_encoder, label_encoders=label_encoders, columns_to_numpy=columns_to_numpy)\n",
    "X_test_encoded = encode_dataset(X=X_test, one_hot_encoder=one_hot_encoder, label_encoders=label_encoders, columns_to_numpy=columns_to_numpy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo en to-expose que alcanzo el mayor F1-score fue con XGBoost y alcanzo el valor de 0.30. Ahora procederemos a crear otro modelo base para también utilizarlo en la comparación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomClassifier:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = y.unique()\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [random.choice(self.classes) for _ in range(len(X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomClassifier()\n",
    "model.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22411 22110]\n",
      " [ 5040  5003]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.50      0.62     44521\n",
      "        True       0.18      0.50      0.27     10043\n",
      "\n",
      "    accuracy                           0.50     54564\n",
      "   macro avg       0.50      0.50      0.45     54564\n",
      "weighted avg       0.70      0.50      0.56     54564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train_encoded)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2806 2772]\n",
      " [ 642  601]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.50      0.62      5578\n",
      "        True       0.18      0.48      0.26      1243\n",
      "\n",
      "    accuracy                           0.50      6821\n",
      "   macro avg       0.50      0.49      0.44      6821\n",
      "weighted avg       0.70      0.50      0.56      6821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid_encoded)\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo random podemos ver que alcanzamos un F1-score de 0.26 en el los datos de validación lo cual ya no es mejor. <br>\n",
    "Por lo que el modelo base sera el XGBoost de to-expose que tiene un F1-score de 0.30."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, realizamos un grid search para buscar los parametros iniciales del modelo XGBoost."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo XGBoost con one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use cross validation\n",
    "X_train_valid_encoded = np.concatenate((X_train_encoded, X_valid_encoded), axis=0)\n",
    "y_train_valid = np.concatenate((y_train, y_valid), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.404, test=0.393) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.406, test=0.392) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.343, test=0.338) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.349, test=0.344) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.421, test=0.402) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.416, test=0.399) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.354, test=0.347) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.361, test=0.352) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.440, test=0.408) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.438, test=0.405) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.370, test=0.354) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.380, test=0.358) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.476, test=0.415) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.474, test=0.413) total time=   0.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.392, test=0.363) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.400, test=0.366) total time=   0.8s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.897, test=0.362) total time=   2.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.899, test=0.354) total time=   2.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.882, test=0.376) total time=   2.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.885, test=0.363) total time=   2.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.911, test=0.359) total time=   3.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.910, test=0.352) total time=   4.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.909, test=0.369) total time=   3.7s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.908, test=0.358) total time=   3.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.429, test=0.405) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.431, test=0.401) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.365, test=0.354) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.369, test=0.354) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.452, test=0.408) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.452, test=0.408) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.362) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.384, test=0.360) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.498, test=0.411) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.499, test=0.410) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.418, test=0.372) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.417, test=0.370) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.553, test=0.415) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.549, test=0.409) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.458, test=0.379) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.451, test=0.379) total time=   0.6s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.912, test=0.351) total time=   1.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.911, test=0.344) total time=   2.0s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.912, test=0.363) total time=   1.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.911, test=0.348) total time=   1.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.912, test=0.348) total time=   2.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.911, test=0.344) total time=   2.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.912, test=0.360) total time=   2.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.911, test=0.344) total time=   2.7s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.403, test=0.394) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.404, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.342, test=0.338) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.348, test=0.343) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.419, test=0.402) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.416, test=0.399) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.354, test=0.347) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.361, test=0.353) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.440, test=0.409) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.434, test=0.404) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.369, test=0.354) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.378, test=0.358) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.471, test=0.417) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.465, test=0.411) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.391, test=0.365) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.397, test=0.365) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.877, test=0.373) total time=   2.1s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.878, test=0.366) total time=   2.9s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.837, test=0.380) total time=   2.0s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.850, test=0.380) total time=   2.1s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.905, test=0.361) total time=   3.4s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.906, test=0.354) total time=   3.7s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.897, test=0.370) total time=   3.5s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.899, test=0.366) total time=   3.7s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.429, test=0.405) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.428, test=0.401) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.365, test=0.356) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.372, test=0.358) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.452, test=0.411) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.449, test=0.405) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.363) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.385, test=0.364) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.492, test=0.410) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.495, test=0.412) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.415, test=0.373) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.416, test=0.372) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.550, test=0.412) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.548, test=0.411) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.457, test=0.381) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.455, test=0.382) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.910, test=0.354) total time=   1.5s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.910, test=0.350) total time=   1.5s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.908, test=0.364) total time=   1.5s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.909, test=0.360) total time=   1.7s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.912, test=0.350) total time=   2.4s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.911, test=0.347) total time=   3.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.912, test=0.361) total time=   2.4s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.911, test=0.354) total time=   2.4s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.396, test=0.390) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.387) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.341, test=0.337) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.346, test=0.341) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.396, test=0.390) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.387) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.340, test=0.337) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.346, test=0.341) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.406, test=0.397) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.409, test=0.395) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.353, test=0.346) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.359, test=0.346) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.405, test=0.397) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.409, test=0.395) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.352, test=0.345) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.358, test=0.346) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.423, test=0.403) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.420, test=0.398) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.378, test=0.358) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.358) total time=   0.4s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.422, test=0.403) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.420, test=0.398) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.378, test=0.358) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.357) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.399, test=0.393) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.386) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.342, test=0.339) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.350, test=0.343) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.399, test=0.393) total time=   0.5s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.386) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.342, test=0.339) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.350, test=0.343) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.413, test=0.400) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.410, test=0.394) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.355, test=0.347) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.358, test=0.346) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.413, test=0.400) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.410, test=0.394) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.355, test=0.347) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.358, test=0.346) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.424, test=0.403) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.421, test=0.397) total time=   0.1s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.378, test=0.355) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.391, test=0.361) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.424, test=0.403) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.421, test=0.397) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.378, test=0.355) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.391, test=0.361) total time=   0.5s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.390) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.397, test=0.387) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.339, test=0.336) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.346, test=0.341) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.390) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.397, test=0.387) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.338, test=0.335) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.346, test=0.341) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.406, test=0.397) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.407, test=0.392) total time=   0.1s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.351, test=0.344) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.357, test=0.346) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.406, test=0.397) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.407, test=0.393) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.350, test=0.344) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.357, test=0.346) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.423, test=0.404) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.419, test=0.400) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.375, test=0.357) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.358) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.423, test=0.404) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.419, test=0.400) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.374, test=0.357) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.381, test=0.358) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.400, test=0.393) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.396, test=0.387) total time=   0.1s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.340, test=0.338) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.349, test=0.343) total time=   0.1s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.400, test=0.393) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.396, test=0.387) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.340, test=0.338) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.349, test=0.343) total time=   0.4s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.408, test=0.397) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.410, test=0.397) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.350, test=0.343) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.358, test=0.346) total time=   0.1s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.408, test=0.397) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.410, test=0.397) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.350, test=0.343) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.358, test=0.346) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.423, test=0.400) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.417, test=0.398) total time=   0.7s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.379, test=0.357) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.355) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.423, test=0.400) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.417, test=0.398) total time=   0.4s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.379, test=0.357) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.355) total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;gamma&#x27;: [0, 20], &#x27;lambda&#x27;: [0.1, 1],\n",
       "                         &#x27;learning_rate&#x27;: [0.1, 0.3], &#x27;max_depth&#x27;: [4, 6, 20],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100], &#x27;scale_pos_weight&#x27;: [5, 10],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;hist&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;gamma&#x27;: [0, 20], &#x27;lambda&#x27;: [0.1, 1],\n",
       "                         &#x27;learning_rate&#x27;: [0.1, 0.3], &#x27;max_depth&#x27;: [4, 6, 20],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100], &#x27;scale_pos_weight&#x27;: [5, 10],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;hist&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={'gamma': [0, 20], 'lambda': [0.1, 1],\n",
       "                         'learning_rate': [0.1, 0.3], 'max_depth': [4, 6, 20],\n",
       "                         'n_estimators': [50, 100], 'scale_pos_weight': [5, 10],\n",
       "                         'tree_method': ['hist']},\n",
       "             return_train_score=True, scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_grid = {'max_depth': [4, 6, 20], \n",
    "                   'learning_rate': [0.1, 0.3],\n",
    "                   'n_estimators': [50, 100], \n",
    "                   'gamma': [0, 20], \n",
    "                   'lambda': [0.1, 1],\n",
    "                   'scale_pos_weight': [5, 10],\n",
    "                   'tree_method': ['hist']\n",
    "                   }\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "xgb_gscv = GridSearchCV(model, parameters_grid, cv=2, scoring=\"f1\", return_train_score=True, verbose=3, n_jobs=1)\n",
    "xgb_gscv.fit(X_train_valid_encoded, y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gamma  lambda  learning_rate  max_depth  n_estimators  scale_pos_weight  \\\n",
      "6       0     0.1            0.1          6           100                 5   \n",
      "30      0     1.0            0.1          6           100                 5   \n",
      "18      0     0.1            0.3          6           100                 5   \n",
      "42      0     1.0            0.3          6           100                 5   \n",
      "40      0     1.0            0.3          6            50                 5   \n",
      "..    ...     ...            ...        ...           ...               ...   \n",
      "25      0     1.0            0.1          4            50                10   \n",
      "49     20     0.1            0.1          4            50                10   \n",
      "51     20     0.1            0.1          4           100                10   \n",
      "73     20     1.0            0.1          4            50                10   \n",
      "75     20     1.0            0.1          4           100                10   \n",
      "\n",
      "   tree_method   test_f1  train_f1  \n",
      "6         hist  0.413728  0.475064  \n",
      "30        hist  0.413513  0.468410  \n",
      "18        hist  0.411828  0.550989  \n",
      "42        hist  0.411648  0.548699  \n",
      "40        hist  0.410730  0.493386  \n",
      "..         ...       ...       ...  \n",
      "25        hist  0.340055  0.345224  \n",
      "49        hist  0.338948  0.343485  \n",
      "51        hist  0.338592  0.343177  \n",
      "73        hist  0.338312  0.342562  \n",
      "75        hist  0.338175  0.342240  \n",
      "\n",
      "[96 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "cv_results = xgb_gscv.cv_results_\n",
    "cv_results = pd.concat([pd.DataFrame(cv_results[\"params\"]),\n",
    "                        pd.DataFrame(cv_results[\"mean_test_score\"], columns=[\"test_f1\"]),\n",
    "                        pd.DataFrame(cv_results[\"mean_train_score\"], columns=[\"train_f1\"])],\n",
    "                       axis=1)\n",
    "print(cv_results.sort_values(by=\"test_f1\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results\n",
      "[[32667 11854]\n",
      " [ 1612  8431]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.73      0.83     44521\n",
      "        True       0.42      0.84      0.56     10043\n",
      "\n",
      "    accuracy                           0.75     54564\n",
      "   macro avg       0.68      0.79      0.69     54564\n",
      "weighted avg       0.85      0.75      0.78     54564\n",
      "\n",
      "Validation results\n",
      "[[3851 1727]\n",
      " [ 442  801]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.69      0.78      5578\n",
      "        True       0.32      0.64      0.42      1243\n",
      "\n",
      "    accuracy                           0.68      6821\n",
      "   macro avg       0.61      0.67      0.60      6821\n",
      "weighted avg       0.79      0.68      0.72      6821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {        \n",
    "    'max_depth': 20, \n",
    "    'learning_rate': 0.3,\n",
    "    'n_estimators': 100, \n",
    "    'gamma': 20, \n",
    "    'lambda': 0.1,\n",
    "    'scale_pos_weight': 5\n",
    "}\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "print(\"Training results\")\n",
    "y_pred = model.predict(X_train_encoded)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Validation results\")\n",
    "y_pred = model.predict(X_valid_encoded)\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo mejora bastante en su F1-score de validación pero podemos ver que hay over-fitting.<br> \n",
    "Podriamos mover algunos hiper parametros para arreglar el over fitting pero primero probaremos XGBoost pero con category encoders en vez de one hot encoders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo XGBoost con category encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_category_encoder(X_train: pd.DataFrame, y_train: pd.DataFrame, columns: list) -> ce.GLMMEncoder:\n",
    "    category_encoder = ce.GLMMEncoder(binomial_target = True)\n",
    "    category_encoder.fit(X_train[columns], y_train)\n",
    "    return category_encoder\n",
    "\n",
    "def encode_category_columns(X: pd.DataFrame, category_encoder: ce.GLMMEncoder) -> np.array:\n",
    "    columns = category_encoder.feature_names_out_\n",
    "    return category_encoder.transform(X[columns])\n",
    "\n",
    "def encode_dataset(X: pd.DataFrame, category_encoder: ce.GLMMEncoder, label_encoders: dict, columns_to_numpy: list) -> np.array:\n",
    "    not_encoded_variables = transform_to_numpy(X=X, columns=columns_to_numpy)\n",
    "    label_encodes = encode_label_columns(X=X, label_encoders=label_encoders)\n",
    "    category_encodes = encode_category_columns(X=X, category_encoder=category_encoder)\n",
    "    return np.concatenate([not_encoded_variables, label_encodes, category_encodes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_encoders_columns = ['Des-I', 'Emp-I', 'Des-O', 'Emp-O', 'TIPOVUELO', 'is_high_season']\n",
    "category_encoder = create_category_encoder(X_train=X_train, y_train=y_train, columns=category_encoders_columns)\n",
    "\n",
    "label_columns_with_values = {\n",
    "    'DIANOM': [\"Lunes\", \"Martes\", \"Miercoles\", \"Jueves\", \"Viernes\", \"Sabado\", \"Domingo\"], \n",
    "    'day_period': [\"morning\", \"afternoon\", \"evening\"]\n",
    "}\n",
    "label_encoders = create_label_encoders(columns_with_values=label_columns_with_values)\n",
    "\n",
    "columns_to_numpy = ['DIA', 'MES', 'AÑO']\n",
    "\n",
    "X_train_encoded = encode_dataset(X=X_train, category_encoder=category_encoder, label_encoders=label_encoders, columns_to_numpy=columns_to_numpy)\n",
    "X_valid_encoded = encode_dataset(X=X_valid, category_encoder=category_encoder, label_encoders=label_encoders, columns_to_numpy=columns_to_numpy)\n",
    "X_test_encoded = encode_dataset(X=X_test, category_encoder=category_encoder, label_encoders=label_encoders, columns_to_numpy=columns_to_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use cross validation\n",
    "X_train_valid_encoded = np.concatenate((X_train_encoded, X_valid_encoded), axis=0)\n",
    "y_train_valid = np.concatenate((y_train, y_valid), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.404, test=0.393) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.406, test=0.392) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.343, test=0.338) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.349, test=0.344) total time=   0.0s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.421, test=0.402) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.416, test=0.399) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.354, test=0.347) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.361, test=0.352) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.440, test=0.408) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.438, test=0.405) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.370, test=0.354) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.380, test=0.358) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.476, test=0.415) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.474, test=0.413) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.392, test=0.363) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.400, test=0.366) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.897, test=0.362) total time=   1.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.899, test=0.354) total time=   1.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.882, test=0.376) total time=   1.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.885, test=0.363) total time=   1.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.911, test=0.359) total time=   2.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.910, test=0.352) total time=   2.9s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.909, test=0.369) total time=   3.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.908, test=0.358) total time=   2.7s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.429, test=0.405) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.431, test=0.401) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.365, test=0.354) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.369, test=0.354) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.452, test=0.408) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.452, test=0.408) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.362) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.384, test=0.360) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.498, test=0.411) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.499, test=0.410) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.418, test=0.372) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.417, test=0.370) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.553, test=0.415) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.549, test=0.409) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.458, test=0.379) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.451, test=0.379) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.912, test=0.351) total time=   1.6s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.911, test=0.344) total time=   1.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.912, test=0.363) total time=   1.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.911, test=0.348) total time=   1.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.912, test=0.348) total time=   2.0s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.911, test=0.344) total time=   2.1s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.912, test=0.360) total time=   1.9s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.911, test=0.344) total time=   2.1s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.403, test=0.394) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.404, test=0.392) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.342, test=0.338) total time=   0.1s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.348, test=0.343) total time=   0.1s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.419, test=0.402) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.416, test=0.399) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.354, test=0.347) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.361, test=0.353) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.440, test=0.409) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.434, test=0.404) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.369, test=0.354) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.378, test=0.358) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.471, test=0.417) total time=   0.6s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.465, test=0.411) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.391, test=0.365) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.397, test=0.365) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.877, test=0.373) total time=   4.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.878, test=0.366) total time=   2.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.837, test=0.380) total time=   2.3s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.850, test=0.380) total time=   2.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.905, test=0.361) total time=   3.5s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.906, test=0.354) total time=   3.4s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.897, test=0.370) total time=   3.7s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.899, test=0.366) total time=   3.9s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.429, test=0.405) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.428, test=0.401) total time=   2.8s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.365, test=0.356) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.372, test=0.358) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.452, test=0.411) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.449, test=0.405) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.363) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.385, test=0.364) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.492, test=0.410) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.495, test=0.412) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.415, test=0.373) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.416, test=0.372) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.550, test=0.412) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.548, test=0.411) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.457, test=0.381) total time=   3.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.455, test=0.382) total time=   0.7s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.910, test=0.354) total time=   2.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.910, test=0.350) total time=   6.6s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.908, test=0.364) total time=   2.2s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.909, test=0.360) total time=   2.9s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.912, test=0.350) total time=   4.5s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.911, test=0.347) total time=   6.0s\n",
      "[CV 1/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.912, test=0.361) total time=   4.6s\n",
      "[CV 2/2] END gamma=0, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.911, test=0.354) total time=   3.9s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.396, test=0.390) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.387) total time=   0.4s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.341, test=0.337) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.346, test=0.341) total time=   0.4s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.396, test=0.390) total time=   0.5s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.387) total time=   0.4s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.340, test=0.337) total time=   0.7s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.346, test=0.341) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.406, test=0.397) total time=   0.4s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.409, test=0.395) total time=   0.6s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.353, test=0.346) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.359, test=0.346) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.405, test=0.397) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.409, test=0.395) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.352, test=0.345) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.358, test=0.346) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.423, test=0.403) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.420, test=0.398) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.378, test=0.358) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.358) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.422, test=0.403) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.420, test=0.398) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.378, test=0.358) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.357) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.399, test=0.393) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.386) total time=   0.4s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.342, test=0.339) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.350, test=0.343) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.399, test=0.393) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.386) total time=   0.4s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.342, test=0.339) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.350, test=0.343) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.413, test=0.400) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.410, test=0.394) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.355, test=0.347) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.358, test=0.346) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.413, test=0.400) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.410, test=0.394) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.355, test=0.347) total time=   0.4s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.358, test=0.346) total time=   0.5s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.424, test=0.403) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.421, test=0.397) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.378, test=0.355) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.391, test=0.361) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.424, test=0.403) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.421, test=0.397) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.378, test=0.355) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=0.1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.391, test=0.361) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.390) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.397, test=0.387) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.339, test=0.336) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.346, test=0.341) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.398, test=0.390) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.397, test=0.387) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.338, test=0.335) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.346, test=0.341) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.406, test=0.397) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.407, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.351, test=0.344) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.357, test=0.346) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.406, test=0.397) total time=   0.4s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.407, test=0.393) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.350, test=0.344) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.357, test=0.346) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.423, test=0.404) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.419, test=0.400) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.375, test=0.357) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.358) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.423, test=0.404) total time=   0.3s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.419, test=0.400) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.374, test=0.357) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.1, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.381, test=0.358) total time=   0.3s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.400, test=0.393) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.396, test=0.387) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.340, test=0.338) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.349, test=0.343) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.400, test=0.393) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.396, test=0.387) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.340, test=0.338) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=4, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.349, test=0.343) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.408, test=0.397) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.410, test=0.397) total time=   0.1s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.350, test=0.343) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.358, test=0.346) total time=   0.1s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.408, test=0.397) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.410, test=0.397) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.350, test=0.343) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=6, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.358, test=0.346) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.423, test=0.400) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=5, tree_method=hist;, score=(train=0.417, test=0.398) total time=   0.1s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.379, test=0.357) total time=   0.1s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=50, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.355) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.423, test=0.400) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=5, tree_method=hist;, score=(train=0.417, test=0.398) total time=   0.2s\n",
      "[CV 1/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.379, test=0.357) total time=   0.2s\n",
      "[CV 2/2] END gamma=20, lambda=1, learning_rate=0.3, max_depth=20, n_estimators=100, scale_pos_weight=10, tree_method=hist;, score=(train=0.382, test=0.355) total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;gamma&#x27;: [0, 20], &#x27;lambda&#x27;: [0.1, 1],\n",
       "                         &#x27;learning_rate&#x27;: [0.1, 0.3], &#x27;max_depth&#x27;: [4, 6, 20],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100], &#x27;scale_pos_weight&#x27;: [5, 10],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;hist&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;gamma&#x27;: [0, 20], &#x27;lambda&#x27;: [0.1, 1],\n",
       "                         &#x27;learning_rate&#x27;: [0.1, 0.3], &#x27;max_depth&#x27;: [4, 6, 20],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100], &#x27;scale_pos_weight&#x27;: [5, 10],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;hist&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={'gamma': [0, 20], 'lambda': [0.1, 1],\n",
       "                         'learning_rate': [0.1, 0.3], 'max_depth': [4, 6, 20],\n",
       "                         'n_estimators': [50, 100], 'scale_pos_weight': [5, 10],\n",
       "                         'tree_method': ['hist']},\n",
       "             return_train_score=True, scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_grid = {'max_depth': [4, 6, 20], \n",
    "                   'learning_rate': [0.1, 0.3],\n",
    "                   'n_estimators': [50, 100], \n",
    "                   'gamma': [0, 20], \n",
    "                   'lambda': [0.1, 1],\n",
    "                   'scale_pos_weight': [5, 10],\n",
    "                   'tree_method': ['hist']}\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "xgb_gscv = GridSearchCV(model, parameters_grid, cv=2, scoring=\"f1\", return_train_score=True, verbose=3, n_jobs=1)\n",
    "xgb_gscv.fit(X_train_valid_encoded, y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gamma  lambda  learning_rate  max_depth  n_estimators  scale_pos_weight  \\\n",
      "6       0     0.1            0.1          6           100                 5   \n",
      "30      0     1.0            0.1          6           100                 5   \n",
      "18      0     0.1            0.3          6           100                 5   \n",
      "42      0     1.0            0.3          6           100                 5   \n",
      "40      0     1.0            0.3          6            50                 5   \n",
      "..    ...     ...            ...        ...           ...               ...   \n",
      "25      0     1.0            0.1          4            50                10   \n",
      "49     20     0.1            0.1          4            50                10   \n",
      "51     20     0.1            0.1          4           100                10   \n",
      "73     20     1.0            0.1          4            50                10   \n",
      "75     20     1.0            0.1          4           100                10   \n",
      "\n",
      "   tree_method   test_f1  train_f1  \n",
      "6         hist  0.413728  0.475064  \n",
      "30        hist  0.413513  0.468410  \n",
      "18        hist  0.411828  0.550989  \n",
      "42        hist  0.411648  0.548699  \n",
      "40        hist  0.410730  0.493386  \n",
      "..         ...       ...       ...  \n",
      "25        hist  0.340055  0.345224  \n",
      "49        hist  0.338948  0.343485  \n",
      "51        hist  0.338592  0.343177  \n",
      "73        hist  0.338312  0.342562  \n",
      "75        hist  0.338175  0.342240  \n",
      "\n",
      "[96 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "cv_results = xgb_gscv.cv_results_\n",
    "cv_results = pd.concat([pd.DataFrame(cv_results[\"params\"]),\n",
    "                        pd.DataFrame(cv_results[\"mean_test_score\"], columns=[\"test_f1\"]),\n",
    "                        pd.DataFrame(cv_results[\"mean_train_score\"], columns=[\"train_f1\"])],\n",
    "                       axis=1)\n",
    "print(cv_results.sort_values(by=\"test_f1\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results\n",
      "[[28695 15826]\n",
      " [ 2409  7634]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.64      0.76     44521\n",
      "        True       0.33      0.76      0.46     10043\n",
      "\n",
      "    accuracy                           0.67     54564\n",
      "   macro avg       0.62      0.70      0.61     54564\n",
      "weighted avg       0.81      0.67      0.70     54564\n",
      "\n",
      "Validation results\n",
      "[[3528 2050]\n",
      " [ 383  860]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.63      0.74      5578\n",
      "        True       0.30      0.69      0.41      1243\n",
      "\n",
      "    accuracy                           0.64      6821\n",
      "   macro avg       0.60      0.66      0.58      6821\n",
      "weighted avg       0.79      0.64      0.68      6821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {        \n",
    "    'max_depth': 6, \n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100, \n",
    "    'gamma': 0, \n",
    "    'lambda': 0.1,\n",
    "    'scale_pos_weight': 5\n",
    "}\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "print(\"Training results\")\n",
    "y_pred = model.predict(X_train_encoded)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Validation results\")\n",
    "y_pred = model.predict(X_valid_encoded)\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que aqui encontramos un resultado ligeramente peor, pero el over fitting se reduce bastante por lo que utilizaremos los category encoders.<br>\n",
    "Ahora buscaremos solucionar el over fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 80 candidates, totalling 160 fits\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.476, test=0.415) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.474, test=0.413) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.483, test=0.415) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.483, test=0.414) total time=   0.6s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.482, test=0.416) total time=   0.6s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.479, test=0.415) total time=   0.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.484, test=0.416) total time=   0.7s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.483, test=0.418) total time=   0.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.479, test=0.416) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.469, test=0.415) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.481, test=0.416) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.482, test=0.414) total time=   0.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.482, test=0.417) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.483, test=0.415) total time=   0.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.482, test=0.415) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.479, test=0.414) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.475, test=0.415) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.475, test=0.413) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.485, test=0.414) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.483, test=0.412) total time=   0.7s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.483, test=0.415) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.480, test=0.417) total time=   0.6s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.482, test=0.413) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.479, test=0.413) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.473, test=0.416) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.474, test=0.414) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.484, test=0.416) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.483, test=0.416) total time=   0.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.489, test=0.418) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.482, test=0.415) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.486, test=0.414) total time=   0.5s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=0, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.480, test=0.413) total time=   0.6s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.404, test=0.394) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.401, test=0.391) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.404, test=0.395) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.401, test=0.393) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.403, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.402, test=0.391) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.406, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.402, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.404, test=0.394) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.401, test=0.391) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.404, test=0.395) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.402, test=0.393) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.403, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.402, test=0.391) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.406, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.402, test=0.392) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.404, test=0.395) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.401, test=0.391) total time=   0.2s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.404, test=0.395) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.401, test=0.393) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.403, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.402, test=0.391) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.406, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.403, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.404, test=0.395) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.401, test=0.391) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.404, test=0.395) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.401, test=0.393) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.403, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.402, test=0.391) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.406, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=8, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.403, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.404, test=0.393) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.401, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.407, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.401, test=0.392) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.405, test=0.395) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.402, test=0.391) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.405, test=0.396) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.403, test=0.394) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.405, test=0.394) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.401, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.408, test=0.397) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.401, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.405, test=0.395) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.402, test=0.391) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.405, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.403, test=0.394) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.404, test=0.393) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.401, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.406, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.401, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.406, test=0.395) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.402, test=0.391) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.405, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.402, test=0.395) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.406, test=0.393) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.401, test=0.392) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.406, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.401, test=0.392) total time=   0.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.406, test=0.395) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.402, test=0.391) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.405, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=9, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.402, test=0.395) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.407, test=0.395) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.407, test=0.394) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.411, test=0.399) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.405, test=0.395) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.408, test=0.397) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.406, test=0.395) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.409, test=0.398) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.405, test=0.395) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.405, test=0.395) total time=   0.2s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.407, test=0.394) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.411, test=0.398) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.405, test=0.395) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.408, test=0.397) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.406, test=0.398) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.409, test=0.398) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.405, test=0.395) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.406, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.407, test=0.394) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.410, test=0.399) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.405, test=0.395) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.408, test=0.397) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.406, test=0.398) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.408, test=0.398) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.405, test=0.394) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.406, test=0.396) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.407, test=0.394) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.410, test=0.399) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.405, test=0.395) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.408, test=0.397) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.406, test=0.398) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.408, test=0.398) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=10, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.404, test=0.395) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.425, test=0.403) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.424, test=0.402) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.428, test=0.408) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.423, test=0.403) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.429, test=0.407) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.426, test=0.405) total time=   0.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.431, test=0.405) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.427, test=0.404) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.426, test=0.405) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.424, test=0.403) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.428, test=0.405) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.424, test=0.403) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.429, test=0.409) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.425, test=0.403) total time=   0.5s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.431, test=0.406) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.9, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.427, test=0.403) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.426, test=0.405) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.421, test=0.401) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.429, test=0.405) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.423, test=0.402) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.428, test=0.408) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.425, test=0.403) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.429, test=0.406) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.8, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.427, test=0.402) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.425, test=0.404) total time=   0.3s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=1, tree_method=hist;, score=(train=0.421, test=0.402) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.427, test=0.407) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.9, tree_method=hist;, score=(train=0.425, test=0.403) total time=   0.4s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.429, test=0.407) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.8, tree_method=hist;, score=(train=0.424, test=0.403) total time=   0.3s\n",
      "[CV 1/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.430, test=0.406) total time=   0.4s\n",
      "[CV 2/2] END gamma=0, lambda=0.1, learning_rate=0.1, max_depth=6, max_leaves=20, min_child_weight=0.7, n_estimators=100, scale_pos_weight=5, subsample=0.7, tree_method=hist;, score=(train=0.424, test=0.403) total time=   0.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;gamma&#x27;: [0], &#x27;lambda&#x27;: [0.1], &#x27;learning_rate&#x27;: [0.1],\n",
       "                         &#x27;max_depth&#x27;: [6], &#x27;max_leaves&#x27;: [0, 8, 9, 10, 20],\n",
       "                         &#x27;min_child_weight&#x27;: [1, 0.9, 0.8, 0.7],\n",
       "                         &#x27;n_estimators&#x27;: [100], &#x27;scale_pos_weight&#x27;: [5],\n",
       "                         &#x27;subsample&#x27;: [1, 0.9, 0.8, 0.7],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;hist&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;gamma&#x27;: [0], &#x27;lambda&#x27;: [0.1], &#x27;learning_rate&#x27;: [0.1],\n",
       "                         &#x27;max_depth&#x27;: [6], &#x27;max_leaves&#x27;: [0, 8, 9, 10, 20],\n",
       "                         &#x27;min_child_weight&#x27;: [1, 0.9, 0.8, 0.7],\n",
       "                         &#x27;n_estimators&#x27;: [100], &#x27;scale_pos_weight&#x27;: [5],\n",
       "                         &#x27;subsample&#x27;: [1, 0.9, 0.8, 0.7],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;hist&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={'gamma': [0], 'lambda': [0.1], 'learning_rate': [0.1],\n",
       "                         'max_depth': [6], 'max_leaves': [0, 8, 9, 10, 20],\n",
       "                         'min_child_weight': [1, 0.9, 0.8, 0.7],\n",
       "                         'n_estimators': [100], 'scale_pos_weight': [5],\n",
       "                         'subsample': [1, 0.9, 0.8, 0.7],\n",
       "                         'tree_method': ['hist']},\n",
       "             return_train_score=True, scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_grid = {'max_depth': [6], \n",
    "                   'learning_rate': [0.1],\n",
    "                   'n_estimators': [100], \n",
    "                   'gamma': [0], \n",
    "                   'lambda': [0.1],\n",
    "                   'scale_pos_weight': [5],\n",
    "                   'subsample': [1, 0.9, 0.8, 0.7],\n",
    "                   'max_leaves': [0, 8, 9, 10, 20],\n",
    "                   'min_child_weight': [1, 0.9, 0.8, 0.7],\n",
    "                   'tree_method': ['hist']\n",
    "                   }\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "xgb_gscv = GridSearchCV(model, parameters_grid, cv=2, scoring=\"f1\", return_train_score=True, verbose=3, n_jobs=1)\n",
    "xgb_gscv.fit(X_train_valid_encoded, y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma                      0\n",
      "lambda                   0.1\n",
      "learning_rate            0.1\n",
      "max_depth                  6\n",
      "max_leaves                20\n",
      "min_child_weight         0.9\n",
      "n_estimators             100\n",
      "scale_pos_weight           5\n",
      "subsample                0.8\n",
      "tree_method             hist\n",
      "test_f1             0.406173\n",
      "train_f1             0.42688\n",
      "Name: 70, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cv_results = xgb_gscv.cv_results_\n",
    "cv_results = pd.concat([pd.DataFrame(cv_results[\"params\"]),\n",
    "                        pd.DataFrame(cv_results[\"mean_test_score\"], columns=[\"test_f1\"]),\n",
    "                        pd.DataFrame(cv_results[\"mean_train_score\"], columns=[\"train_f1\"])],\n",
    "                       axis=1)\n",
    "print(cv_results.sort_values(by=\"test_f1\", ascending=False).iloc[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results\n",
      "[[26775 17746]\n",
      " [ 2635  7408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.60      0.72     44521\n",
      "        True       0.29      0.74      0.42     10043\n",
      "\n",
      "    accuracy                           0.63     54564\n",
      "   macro avg       0.60      0.67      0.57     54564\n",
      "weighted avg       0.80      0.63      0.67     54564\n",
      "\n",
      "Validation results\n",
      "[[3352 2226]\n",
      " [ 360  883]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.60      0.72      5578\n",
      "        True       0.28      0.71      0.41      1243\n",
      "\n",
      "    accuracy                           0.62      6821\n",
      "   macro avg       0.59      0.66      0.56      6821\n",
      "weighted avg       0.79      0.62      0.66      6821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {        \n",
    "    'max_depth': 6, \n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100, \n",
    "    'gamma': 0, \n",
    "    'lambda': 0.1,\n",
    "    'scale_pos_weight': 5,\n",
    "    'subsample': 0.8,\n",
    "    'max_leaves': 20,\n",
    "    'min_child_weight': 0.9,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "print(\"Training results\")\n",
    "y_pred = model.predict(X_train_encoded)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Validation results\")\n",
    "y_pred = model.predict(X_valid_encoded)\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se logro aumentar el F1-Score de validación pero si mantenerlo y reducir el F1-score de los datos de entrenamiento evitando asi que se sobre ajusten mucho a los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results\n",
      "[[3317 2176]\n",
      " [ 383  945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.60      0.72      5493\n",
      "        True       0.30      0.71      0.42      1328\n",
      "\n",
      "    accuracy                           0.62      6821\n",
      "   macro avg       0.60      0.66      0.57      6821\n",
      "weighted avg       0.78      0.62      0.66      6821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test results\")\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que en los datos de test el F1-score se generaliza más que en los de Validación por lo que ya nuestros parametros resultantes son:<br>\n",
    "<br>\n",
    "params = {       <br> \n",
    "    'max_depth': 6, <br>\n",
    "    'learning_rate': 0.1,<br>\n",
    "    'n_estimators': 100, <br>\n",
    "    'gamma': 0, <br>\n",
    "    'lambda': 0.1,<br>\n",
    "    'scale_pos_weight': 5,<br>\n",
    "    'subsample': 0.8,<br>\n",
    "    'max_leaves': 20,<br>\n",
    "    'min_child_weight': 0.9,<br>\n",
    "    'tree_method': 'hist'<br>\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, se ha logrado seleccionar el mejor modelo desarrollado por Juan en el notebook \"to-expose\" y se ha mejorado aún más su rendimiento al aplicar técnicas adicionales.<br> Además, se ha comprobado que el modelo supera al modelo base random.\n",
    "\n",
    "Es importante destacar que, al agregar variables de importancia como predicciones del tiempo o días feriados, se podría obtener mejoras significativas en los resultados del modelo.\n",
    "\n",
    "Por último, se ha logrado simplificar los métodos para que sean más fáciles de llevar a producción y se ha mejorado el tiempo de procesamiento de los datos.<br>\n",
    " En general, este trabajo ha sido fundamental para optimizar el modelo y hacerlo más útil y efectivo en situaciones de la vida real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge-mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c2a384837563f38a9223e4c23e081834fad791785f3361468e322ec09524456"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
